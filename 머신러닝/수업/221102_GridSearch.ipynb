{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.목적\n",
    "- iris데이터를 활용하여 그리드 서치를 적용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/87592790/199435028-441ca1e7-b13c-4e33-a158-f18fd73b5712.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리(편집, 생성, 스케일링)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델링(모델학습, 평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Knn_25% 성능 : 0.9473684210526315\n",
      "Knn_35% 성능 : 0.9433962264150944\n",
      "Knn_45% 성능 : 0.9117647058823529\n",
      "Knn_55% 성능 : 0.927710843373494\n",
      "Knn_65% 성능 : 0.9387755102040817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 만든 module로 스케일링 후 훈련셋, 테스트셋 나누기\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.35, random_state=0)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.45, random_state=0)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(x, y, test_size=0.55, random_state=0)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(x, y, test_size=0.65, random_state=0)\n",
    "\n",
    "# param_knn = {'n_neighbors': range(1,1000)}\n",
    "knn = GridSearchCV(KNeighborsClassifier(n_neighbors=11), param_knn, cv=5)\n",
    "# GridSearchCV안에 cv로 교차검증이 내장되어 있음\n",
    "\n",
    "knn.fit(X_train0, y_train0)\n",
    "knn.fit(X_train1, y_train1)\n",
    "knn.fit(X_train2, y_train2)\n",
    "knn.fit(X_train3, y_train3)\n",
    "knn.fit(X_train4, y_train4)\n",
    "\n",
    "print(f\"\"\"\n",
    "Knn_25% 성능 : {knn.score(X_test0, y_test0)}\n",
    "Knn_35% 성능 : {knn.score(X_test1, y_test1)}\n",
    "Knn_45% 성능 : {knn.score(X_test2, y_test2)}\n",
    "Knn_55% 성능 : {knn.score(X_test3, y_test3)}\n",
    "Knn_65% 성능 : {knn.score(X_test4, y_test4)}\n",
    "\"\"\")\n",
    "\n",
    "# 테스트 셋의 데이터가 커질수록(학습데이터가 작을수록) 성능이 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 테스트 셋이 0.25% !!! ==========\n",
      "1번째 교차 검증 정확도 : 0.9737 \n",
      " 학습 데이터 크기 : 112 \n",
      " 검증 데이터 크기 : 38 \n",
      "\n",
      "========== 테스트 셋이 0.25% !!! ==========\n",
      "2번째 교차 검증 정확도 : 0.9737 \n",
      " 학습 데이터 크기 : 112 \n",
      " 검증 데이터 크기 : 38 \n",
      "\n",
      "========== 테스트 셋이 0.25% !!! ==========\n",
      "3번째 교차 검증 정확도 : 0.9737 \n",
      " 학습 데이터 크기 : 112 \n",
      " 검증 데이터 크기 : 38 \n",
      "\n",
      "========== 테스트 셋이 0.25% !!! ==========\n",
      "4번째 교차 검증 정확도 : 0.9737 \n",
      " 학습 데이터 크기 : 112 \n",
      " 검증 데이터 크기 : 38 \n",
      "\n",
      "========== 테스트 셋이 0.25% !!! ==========\n",
      "5번째 교차 검증 정확도 : 0.9737 \n",
      " 학습 데이터 크기 : 112 \n",
      " 검증 데이터 크기 : 38 \n",
      "\n",
      "========== 테스트 셋이 0.35% !!! ==========\n",
      "6번째 교차 검증 정확도 : 0.9434 \n",
      " 학습 데이터 크기 : 97 \n",
      " 검증 데이터 크기 : 53 \n",
      "\n",
      "========== 테스트 셋이 0.35% !!! ==========\n",
      "7번째 교차 검증 정확도 : 0.9434 \n",
      " 학습 데이터 크기 : 97 \n",
      " 검증 데이터 크기 : 53 \n",
      "\n",
      "========== 테스트 셋이 0.35% !!! ==========\n",
      "8번째 교차 검증 정확도 : 0.9434 \n",
      " 학습 데이터 크기 : 97 \n",
      " 검증 데이터 크기 : 53 \n",
      "\n",
      "========== 테스트 셋이 0.35% !!! ==========\n",
      "9번째 교차 검증 정확도 : 0.9434 \n",
      " 학습 데이터 크기 : 97 \n",
      " 검증 데이터 크기 : 53 \n",
      "\n",
      "========== 테스트 셋이 0.35% !!! ==========\n",
      "10번째 교차 검증 정확도 : 0.9434 \n",
      " 학습 데이터 크기 : 97 \n",
      " 검증 데이터 크기 : 53 \n",
      "\n",
      "========== 테스트 셋이 0.45% !!! ==========\n",
      "11번째 교차 검증 정확도 : 0.9412 \n",
      " 학습 데이터 크기 : 82 \n",
      " 검증 데이터 크기 : 68 \n",
      "\n",
      "========== 테스트 셋이 0.45% !!! ==========\n",
      "12번째 교차 검증 정확도 : 0.9412 \n",
      " 학습 데이터 크기 : 82 \n",
      " 검증 데이터 크기 : 68 \n",
      "\n",
      "========== 테스트 셋이 0.45% !!! ==========\n",
      "13번째 교차 검증 정확도 : 0.9412 \n",
      " 학습 데이터 크기 : 82 \n",
      " 검증 데이터 크기 : 68 \n",
      "\n",
      "========== 테스트 셋이 0.45% !!! ==========\n",
      "14번째 교차 검증 정확도 : 0.9412 \n",
      " 학습 데이터 크기 : 82 \n",
      " 검증 데이터 크기 : 68 \n",
      "\n",
      "========== 테스트 셋이 0.45% !!! ==========\n",
      "15번째 교차 검증 정확도 : 0.9412 \n",
      " 학습 데이터 크기 : 82 \n",
      " 검증 데이터 크기 : 68 \n",
      "\n",
      "========== 테스트 셋이 0.55% !!! ==========\n",
      "16번째 교차 검증 정확도 : 0.9398 \n",
      " 학습 데이터 크기 : 67 \n",
      " 검증 데이터 크기 : 83 \n",
      "\n",
      "========== 테스트 셋이 0.55% !!! ==========\n",
      "17번째 교차 검증 정확도 : 0.9398 \n",
      " 학습 데이터 크기 : 67 \n",
      " 검증 데이터 크기 : 83 \n",
      "\n",
      "========== 테스트 셋이 0.55% !!! ==========\n",
      "18번째 교차 검증 정확도 : 0.9398 \n",
      " 학습 데이터 크기 : 67 \n",
      " 검증 데이터 크기 : 83 \n",
      "\n",
      "========== 테스트 셋이 0.55% !!! ==========\n",
      "19번째 교차 검증 정확도 : 0.9398 \n",
      " 학습 데이터 크기 : 67 \n",
      " 검증 데이터 크기 : 83 \n",
      "\n",
      "========== 테스트 셋이 0.55% !!! ==========\n",
      "20번째 교차 검증 정확도 : 0.9398 \n",
      " 학습 데이터 크기 : 67 \n",
      " 검증 데이터 크기 : 83 \n",
      "\n",
      "========== 테스트 셋이 0.65% !!! ==========\n",
      "21번째 교차 검증 정확도 : 0.9388 \n",
      " 학습 데이터 크기 : 52 \n",
      " 검증 데이터 크기 : 98 \n",
      "\n",
      "========== 테스트 셋이 0.65% !!! ==========\n",
      "22번째 교차 검증 정확도 : 0.9388 \n",
      " 학습 데이터 크기 : 52 \n",
      " 검증 데이터 크기 : 98 \n",
      "\n",
      "========== 테스트 셋이 0.65% !!! ==========\n",
      "23번째 교차 검증 정확도 : 0.9388 \n",
      " 학습 데이터 크기 : 52 \n",
      " 검증 데이터 크기 : 98 \n",
      "\n",
      "========== 테스트 셋이 0.65% !!! ==========\n",
      "24번째 교차 검증 정확도 : 0.9388 \n",
      " 학습 데이터 크기 : 52 \n",
      " 검증 데이터 크기 : 98 \n",
      "\n",
      "========== 테스트 셋이 0.65% !!! ==========\n",
      "25번째 교차 검증 정확도 : 0.9388 \n",
      " 학습 데이터 크기 : 52 \n",
      " 검증 데이터 크기 : 98 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = GridSearchCV(KNeighborsClassifier(n_neighbors=11), param_knn, cv=5)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "idx_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for per in [0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "    for train_index, test_index in skf.split(x,y):\n",
    "        print(f\"========== 테스트 셋이 {per}% !!! ==========\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=per, random_state=0)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        \n",
    "        idx_iter += 1\n",
    "        accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "        \n",
    "        train_size = x_train.shape[0]\n",
    "        test_size = x_test.shape[0]\n",
    "        \n",
    "        # print(f'{idx_iter}번째 교차 검증 정확도 : {accuracy} \\n 학습 데이터 크기 : {train_size} \\n 검증 데이터 크기 : {test_size} \\n')\n",
    "        print(f'{idx_iter}번째 교차 검증 정확도 : {accuracy} ')\n",
    "        cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [67, 52]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [55], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m DT \u001b[39m=\u001b[39m GridSearchCV(DecisionTreeRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), param_dt, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# GridSearchCV안에 cv로 교차검증이 내장되어 있음\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# DT.get_params().keys()\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m DT\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39m최적의 파라미터는? \u001b[39m\u001b[39m{\u001b[39;00mDT\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m최고의 교차검증 점수? \u001b[39m\u001b[39m{\u001b[39;00mDT\u001b[39m.\u001b[39mbest_score_\u001b[39m}\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m최고 성능 모델? \u001b[39m\u001b[39m{\u001b[39;00mDT\u001b[39m.\u001b[39mbest_estimator_\u001b[39m}\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m       \u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[0;32m     19\u001b[0m DT\u001b[39m.\u001b[39mpredict(X_test), DT\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:799\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    797\u001b[0m     refit_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit\n\u001b[1;32m--> 799\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    800\u001b[0m fit_params \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    802\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 378\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [67, 52]"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_dt = {'max_depth':range(1,10),\n",
    "             'max_leaf_nodes': [1,2,3,4,5,6,7,8,9,10],\n",
    "             'min_samples_leaf': range(1,10)\n",
    "             }\n",
    " \n",
    "DT = GridSearchCV(DecisionTreeRegressor(random_state=0), param_dt, cv=5)\n",
    "# GridSearchCV안에 cv로 교차검증이 내장되어 있음\n",
    "# DT.get_params().keys()\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "print(f'''\n",
    "최적의 파라미터는? {DT.best_params_}\n",
    "최고의 교차검증 점수? {DT.best_score_}\n",
    "최고 성능 모델? {DT.best_estimator_}\n",
    "       ''')\n",
    "\n",
    "DT.predict(X_test), DT.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최적의 파라미터는? {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "최고의 교차검증 점수? 0.9692307692307693\n",
      "최고 성능 모델? SVC(C=1, gamma=0.0001, kernel='linear')\n",
      "       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "        0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "        0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "        1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0]),\n",
       " 0.9759036144578314)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_svc = {'C':[0.0001, 0.001, 0.1, 0.5, 1, 10, 20, 30, 40, 50, 60],\n",
    "             'gamma': [0.0001, 0.001, 0.1, 0.5, 1, 10, 20, 30, 40, 50, 60],\n",
    "             'kernel': ['linear']\n",
    "             }\n",
    " \n",
    "SVC = GridSearchCV(SVC(), param_svc, cv=5)\n",
    "# GridSearchCV안에 cv로 교차검증이 내장되어 있음\n",
    "SVC.fit(X_train, y_train)\n",
    "\n",
    "print(f'''\n",
    "최적의 파라미터는? {SVC.best_params_}\n",
    "최고의 교차검증 점수? {SVC.best_score_}\n",
    "최고 성능 모델? {SVC.best_estimator_}\n",
    "       ''')\n",
    "\n",
    "SVC.predict(X_test), SVC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

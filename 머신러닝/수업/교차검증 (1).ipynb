{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[2,1],[2,3],[4,1],[5,6],[7,7],[8,9],[9,10],[6,7],[6,10],[2,8],[7,5]])\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  6  7  8  9 10]\n",
      "[0 1 2]\n",
      "[ 0  1  2  5  6  7  8  9 10]\n",
      "[3 4]\n",
      "[ 0  1  2  3  4  7  8  9 10]\n",
      "[5 6]\n",
      "[ 0  1  2  3  4  5  6  9 10]\n",
      "[7 8]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[ 9 10]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(x_data):\n",
    "    print(train_index)\n",
    "    print(test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold 교차검증 -> 회귀 문제에서 사용\n",
    "- 학습 data와 테스트 data를 n_splits개의 세트로 나누어 검증하는 방법\n",
    "- data set이 적을 때 train data를 늘리기 위해 사용\n",
    "- 여러 개의 train, test data 짝으로 검증과정을 거침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[2,1],[2,3],[4,1],[5,6],[7,7],[8,9],[9,10],[6,7],[6,10],[2,8],[7,5]])\n",
    "y_data = np.array([3,5,9,7,10,2,15,6,4,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.09087045589617082,\n",
       "  0.14634108316388406,\n",
       "  0.2596984905781652,\n",
       "  0.22523882013459684,\n",
       "  0.35657970453058097],\n",
       " [0.33939878660391054,\n",
       "  -0.28777247567478437,\n",
       "  0.06722521416975036,\n",
       "  -9.902863890644971,\n",
       "  -157.7869721150263])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    x_train = np.array(x_data)[train_index]\n",
    "    y_train = np.array(y_data)[train_index]\n",
    "    x_test = np.array(x_data)[test_index]\n",
    "    y_test = np.array(y_data)[test_index]\n",
    "\n",
    "    model_kf = LinearRegression()\n",
    "    model_kf.fit(x_train, y_train)\n",
    "    score = model_kf.score(x_train, y_train)    # R2\n",
    "    train_scores.append(score)\n",
    "    score = model_kf.score(x_test, y_test)\n",
    "    test_scores.append(score)\n",
    "\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21574571086067956"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33.51419689611448"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2값\n",
    "- -, + 부호는 그래프의 기울기\n",
    "- 절대값은 data를 잘 설명하는 정도(-1~1 사이의 값을 가짐) : 너무 커지거나 작아지면 data가 쓰레기라는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0009954 , 0.        , 0.00099564, 0.        , 0.        ]),\n",
       " 'score_time': array([0.        , 0.        , 0.        , 0.00098872, 0.        ]),\n",
       " 'test_score': array([ 3.39398787e-01, -2.87772476e-01,  6.72252142e-02, -9.90286389e+00,\n",
       "        -1.57786972e+02])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "cv_results = cross_validate(model, x_data, y_data)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33.51419689611448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.287772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>-9.902864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-157.786972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.000995    0.000000    0.339399\n",
       "2  0.000996    0.000000    0.067225\n",
       "1  0.000000    0.000000   -0.287772\n",
       "3  0.000000    0.000989   -9.902864\n",
       "4  0.000000    0.000000 -157.786972"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cv_results)\n",
    "df = df.sort_values(by='test_score', ascending=False)   # 내림차순\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.39398787e-01, -2.87772476e-01,  6.72252142e-02, -9.90286389e+00,\n",
       "       -1.57786972e+02])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cross_val_score(model, x_data, y_data, cv=5)\n",
    "cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33.51419689611448"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([\n",
    "    [2,1],\n",
    "    [3,2],\n",
    "    [3,4],\n",
    "    [5,5],\n",
    "    [7,5],\n",
    "    [2,5],\n",
    "    [8,9],\n",
    "    [9,10],\n",
    "    [6, 12],\n",
    "    [9,2],\n",
    "    [6,10],\n",
    "    [2,4]\n",
    "])\n",
    "y_data = np.array([3,5,7,10,12,7,13,13,12,13,12,6])\n",
    "label = ['A','B','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    823\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    824\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    829\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Study\\AI\\2주차\\3일차\\교차검증.ipynb 셀 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Study/AI/2%EC%A3%BC%EC%B0%A8/3%EC%9D%BC%EC%B0%A8/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Study/AI/2%EC%A3%BC%EC%B0%A8/3%EC%9D%BC%EC%B0%A8/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(model, x_data, y_data, return_estimator\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Study/AI/2%EC%A3%BC%EC%B0%A8/3%EC%9D%BC%EC%B0%A8/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# cv_results = cross_validate(model, x_data, y_data, return_estimator=True)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Study/AI/2%EC%A3%BC%EC%B0%A8/3%EC%9D%BC%EC%B0%A8/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv_results\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m         clone(estimator),\n\u001b[0;32m    270\u001b[0m         X,\n\u001b[0;32m    271\u001b[0m         y,\n\u001b[0;32m    272\u001b[0m         scorers,\n\u001b[0;32m    273\u001b[0m         train,\n\u001b[0;32m    274\u001b[0m         test,\n\u001b[0;32m    275\u001b[0m         verbose,\n\u001b[0;32m    276\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    277\u001b[0m         fit_params,\n\u001b[0;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    284\u001b[0m )\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    830\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    831\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 833\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m         clone(estimator),\n\u001b[0;32m    270\u001b[0m         X,\n\u001b[0;32m    271\u001b[0m         y,\n\u001b[0;32m    272\u001b[0m         scorers,\n\u001b[0;32m    273\u001b[0m         train,\n\u001b[0;32m    274\u001b[0m         test,\n\u001b[0;32m    275\u001b[0m         verbose,\n\u001b[0;32m    276\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    277\u001b[0m         fit_params,\n\u001b[0;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    284\u001b[0m )\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:340\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[0;32m    333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m         (\n\u001b[0;32m    335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    338\u001b[0m     )\n\u001b[1;32m--> 340\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    341\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:86\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     84\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m     85\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m---> 86\u001b[0m \u001b[39mfor\u001b[39;00m test_index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m     87\u001b[0m     train_index \u001b[39m=\u001b[39m indices[np\u001b[39m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m     88\u001b[0m     test_index \u001b[39m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:709\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter_test_masks\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 709\u001b[0m     test_folds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_test_folds(X, y)\n\u001b[0;32m    710\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits):\n\u001b[0;32m    711\u001b[0m         \u001b[39myield\u001b[39;00m test_folds \u001b[39m==\u001b[39m i\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:671\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    669\u001b[0m min_groups \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmin(y_counts)\n\u001b[0;32m    670\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mall(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m y_counts):\n\u001b[1;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    672\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_splits=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m cannot be greater than the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    673\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of members in each class.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits)\n\u001b[0;32m    674\u001b[0m     )\n\u001b[0;32m    675\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m min_groups:\n\u001b[0;32m    676\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    677\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    678\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m members, which is less than n_splits=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m         \u001b[39m%\u001b[39m (min_groups, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits),\n\u001b[0;32m    680\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m    681\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "cv_results = cross_validate(model, x_data, y_data, return_estimator=True)\n",
    "# cv_results = cross_validate(model, x_data, y_data, return_estimator=True)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33.51419689611448"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.287772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.902864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-157.786972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.000000         0.0    0.339399\n",
       "2  0.000000         0.0    0.067225\n",
       "1  0.000000         0.0   -0.287772\n",
       "3  0.000998         0.0   -9.902864\n",
       "4  0.000000         0.0 -157.786972"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cv_results)\n",
    "df = df.sort_values(by='test_score', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계층적 k-겹 교차검증(stratified k-fold cross validation)\n",
    "- 분류 모델에 적용\n",
    "- k-겹 교차검증 모델은 k-fold가 원본 data 집합의 레이블 분포를 학습 및 검증 data set에 제대로 분배하지 못하는 문제를 해결\n",
    "- target 값(= 레이블/클래스)의 속성값의 개수를 골고루 넣어주게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차 검증 정확도 : 0.9333 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "2번째 교차 검증 정확도 : 0.9667 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "3번째 교차 검증 정확도 : 1.0 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "4번째 교차 검증 정확도 : 0.9333 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "5번째 교차 검증 정확도 : 1.0 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "idx_iter = 0\n",
    "cv_acc = []\n",
    "\n",
    "# split으로 반환된 인덱스를 이용해서 학습데이터, 테스트데이터를 정의해줌\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    idx_iter += 1\n",
    "    acc = np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "\n",
    "    print('{0}번째 교차 검증 정확도 : {1} \\n 학습 데이터 크기 : {2} \\n 검증 데이터 크기 : {3}'.format(idx_iter,acc,train_size,test_size))\n",
    "    cv_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd #엑셀화 판다스\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys #키보드\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "넘어갔음\n",
      "13페이지에서 끝냅니다.\n",
      "98번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n",
      "102번째 지나감\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tag' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.amazon.com/s?k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&qid=1663294734&ref=sr_pg_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     i\u001b[38;5;241m=\u001b[39m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     33\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     34\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tag' and 'int'"
     ]
    }
   ],
   "source": [
    "# 가져온 데이터를 텍스트화 해서 저장하는 리스트들\n",
    "date_site_list = []\n",
    "star_list = []\n",
    "content_list = []\n",
    "title_list=[]\n",
    "review_all = []\n",
    "\n",
    "# 사이트 가기https://www.amazon.com/ref=nav_logo\n",
    "driver=webdriver.Chrome(ChromeDriverManager().install())\n",
    "#data 창이 뜨고 나서 그걸 움직이는 것\n",
    "#가져오고자 하는 url입력\n",
    "#.get.url(\"URL\")\n",
    "driver.get(\"https://www.amazon.com/ref=nav_logo\")\n",
    "driver.maximize_window()\n",
    "#광고 끄기\n",
    "try: search=driver.find_element_by_xpath('//*[@id=\"nav-main\"]/div[1]/div/div/div[3]/span[1]/span/input').click()\n",
    "except:\n",
    "    print(\"지역 광고가 없습니다! 다음을 진행해 주세요.\")\n",
    "\n",
    "#검색하기\n",
    "search=driver.find_element_by_xpath('//*[@id=\"twotabsearchtextbox\"]')\n",
    "search.clear()\n",
    "# a = str(input(\"검색어를 입력하세요: \"))\n",
    "search.send_keys(coffee machine)\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "i=1 #상품검색 페이지 수\n",
    "while True: \n",
    "    print(f\"=========== 아직 {i}페이지 입니다 ===========\")\n",
    "    k=0\n",
    "    for j in range(1,65):\n",
    "        try:\n",
    "            #각 페이지에서 제품 사이트 들어가기\n",
    "            driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{j}]/div/div/div/div/div[2]/div[1]/h2/a/span').click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            soup=bs(driver.page_source, 'html.parser')\n",
    "\n",
    "            #상품명 가져오기\n",
    "            title_bs=soup.select('h1>span.a-size-large.product-title-word-break')\n",
    "            for P in title_bs:\n",
    "                title_list.append(P.text.strip())\n",
    "\n",
    "            #모든 리뷰보기로 이동하기 위한 url 가져오기\n",
    "            AllReview = soup.select(\"a.a-link-emphasis.a-text-bold\") \n",
    "            AllReview_url = 'https://www.amazon.com/' + AllReview[0][\"href\"]\n",
    "\n",
    "            #모든 리뷰로 이동\n",
    "            driver.get(AllReview_url) \n",
    "            driver.implicitly_wait(5)\n",
    "            print(\"넘어갔음\")\n",
    "\n",
    "            x = 1\n",
    "            while True:\n",
    "                #모든 리뷰의 페이지 소스 가져오기\n",
    "                soup = bs(driver.page_source, \"lxml\") \n",
    "\n",
    "                #원하는 태그 삭제하기(번역)\n",
    "                remove = soup.select(\"span.a-size-base.review-text.review-text-content > span.cr-translated-review-content.aok-hidden\")\n",
    "                for rm in remove:\n",
    "                    rm.extract()\n",
    "\n",
    "                #[Beautiful Soup] CSS를 이용한 코드 가져오기(날짜&장소, 별점, 내용)\n",
    "                date_site = soup.select('div.a-section.celwidget > span.a-size-base.a-color-secondary.review-date') \n",
    "                star = soup.select('div:nth-child(2) > a:nth-child(1) > i > span.a-icon-alt')\n",
    "                content = soup.select('span.a-size-base.review-text.review-text-content > span') \n",
    "\n",
    "                #[Beautiful Soup] 가져온 코드 Text화해서 리스트에 추가하기\n",
    "                for b in range(len(date_site)):\n",
    "                    date_site_list.append(date_site[b].text.replace(\"Reviewed in \", \"\"))\n",
    "                    star_list.append(star[b].text.replace(\" out of 5 stars\", \"\"))\n",
    "                    content_list.append(content[b].text)\n",
    "              \n",
    "                review_all.append(list(date_site_list))\n",
    "                review_all.append(list(star_list))\n",
    "                review_all.append(list(content_list))\n",
    "\n",
    "                # 리뷰 다음페이지로 이동하기 / 더이상 페이지 없으면 멈추기\n",
    "                try:    \n",
    "                    x += 1            \n",
    "                    NextPage = driver.find_element_by_xpath('//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a') \n",
    "                    NextPage.click()\n",
    "                    time.sleep(2)\n",
    "                    driver.refresh()\n",
    "                    driver.implicitly_wait(5)\n",
    "                    time.sleep(2)\n",
    "                except:\n",
    "                    print(f\"{x-1}페이지에서 끝냅니다.\")\n",
    "                    break\n",
    "\n",
    "        # 리뷰를 빠져나올 때 첫번째 검색한 페이지로 가는 부분에서 오류가 발생함. 전 페이지로 가면 리뷰페이지만 있을 수 밖에...    \n",
    "        # driver.back()\n",
    "        # print(\"98번째 지나감\")\n",
    "            k=j+1\n",
    "\n",
    "        except:\n",
    "            print(f\"{j}번째 상품이 없음.\") # 해당하지 않은 제품의 개수를 확인하기 위한 출력문\n",
    "            pass\n",
    "    \n",
    "    i += 1\n",
    "    # 원하는 상품을 검색한 페이지에서 다음페이지로 넘어가는 코드 #2,3,4, .... 페이지로\n",
    "    if i == 1: # 1페이지에서 2페이지에서 xpath값 지정\n",
    "        num1 = 29\n",
    "        num2 = 1\n",
    "        driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{num1}]/div/div/span/a[{num2}]').click()\n",
    "        time.sleep(1)\n",
    "    elif i == 2: # 2페이지에서 3페이지에서 xpath값 지정\n",
    "        num1 = 28\n",
    "        num2 = 3\n",
    "        driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{num1}]/div/div/span/a[{num2}]').click()\n",
    "        time.sleep(1) \n",
    "    elif i == 3:  # 3페이지에서 4페이지에서 xpath값 지정\n",
    "        num1 = 28\n",
    "        num2 = 4\n",
    "        driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{num1}]/div/div/span/a[{num2}]').click()\n",
    "        time.sleep(1)\n",
    "    elif i == 4: # 4페이지에서 5페이지에서 xpath값 지정\n",
    "        num1 = 27\n",
    "        num2 = 5\n",
    "        driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{num1}]/div/div/span/a[{num2}]').click()\n",
    "        time.sleep(1) \n",
    "    else:  \n",
    "        num1 = 28\n",
    "        num2 = 4\n",
    "        driver.find_element_by_xpath(f'//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[{num1}]/div/div/span/a[{num2}]').click()\n",
    "        # 2페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[67]/div/div/span/a[1]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(67) > div > div > span > a:nth-child(3)\n",
    "        # 3페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[66]/div/div/span/a[3]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(66) > div > div > span > a:nth-child(4)\n",
    "        # 4페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[65]/div/div/span/a[4]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(65) > div > div > span > a:nth-child(5)\n",
    "        # 5페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[66]/div/div/span/a[5]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(66) > div > div > span > a:nth-child(6)\n",
    "        # 6페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[66]/div/div/span/a[4]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(66) > div > div > span > a:nth-child(6)\n",
    "        # 7페이지 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[66]/div/div/span/a[4]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(65) > div > div > span > a:nth-child(6)\n",
    "        # 다음페이지 없음 //*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[35]/div/div/span/span[3]\n",
    "        # div.s-matching-dir.sg-col-16-of-20.sg-col.sg-col-8-of-12.sg-col-12-of-16 > div > span:nth-child(4) > div.s-main-slot.s-result-list.s-search-results.sg-row > div:nth-child(36) > div > div > span > span.s-pagination-item.s-pagination-next.s-pagination-disabled\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "    # if k==0:#광고문 제거선언\n",
    "    #     print(\"91번에서 오류\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 121 121\n"
     ]
    }
   ],
   "source": [
    "print(len(date_site_list), len(star_list), len(content_list))\n",
    "\n",
    "#print( \"date_site\", len(date_site),  \"star\", len(star), \"content\", len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 31 31\n",
      "date_site 1 star 1 content 1\n",
      "================1번째=======================\n",
      "This machine makes perfect expresso--rich dark coffee with a tan foam.  Easy to clean the coffee part.  The milk frother is another story.  Very difficult to use correctly and also a pain to clean.  This appliance would be a 5 star but for the frother.  I use a separate tool to froth the milk/half & half.  I recommend this machine for  expresso performance- at a good price point.\n"
     ]
    }
   ],
   "source": [
    "print(len(date_site_list), len(star_list), len(content_list))\n",
    "\n",
    "print( \"date_site\", len(date_site),  \"star\", len(star), \"content\", len(content))\n",
    "\n",
    "x = 1\n",
    "for i in content:\n",
    "    try:    \n",
    "        print(f\"================{x}번째=======================\")\n",
    "        print(i.text)\n",
    "        x += 1\n",
    "    except:\n",
    "        print(f\"{i}번째 오류 \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가져온 데이터를 텍스트화 해서 저장하는 리스트들\n",
    "date_site_list = []\n",
    "star_list = []\n",
    "content_list = []\n",
    "title_list=[]\n",
    "review_all = []\n",
    "\n",
    "# 사이트 가기https://www.amazon.com/ref=nav_logo\n",
    "driver=webdriver.Chrome(ChromeDriverManager().install())\n",
    "#data 창이 뜨고 나서 그걸 움직이는 것\n",
    "#가져오고자 하는 url입력\n",
    "#.get.url(\"URL\")\n",
    "driver.get(\"https://www.amazon.com/s?k=coffee+machine&crid=3G3G5RBAIJZCN&sprefix=%2Caps%2C211&ref=nb_sb_ss_recent_1_0_recent\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#광고 끄기\n",
    "try: search=driver.find_element_by_xpath('//*[@id=\"nav-main\"]/div[1]/div/div/div[3]/span[1]/span/input').click()\n",
    "except:\n",
    "    print(\"지역 광고가 없습니다! 다음을 진행해 주세요.\")\n",
    "\n",
    "soup = bs(driver.page_source, \"lxml\") \n",
    "\n",
    "# driver.close()\n",
    "\n",
    "content = soup.select('''h2.a-size-mini.a-spacing-none.a-color-base.s-line-clamp-4 \n",
    "> a.a-link-normal.s-underline-text.s-underline-link-text.s-link-style.a-text-normal> span.a-size-base.-color-base.a-text-normal''') \n",
    "\n",
    "# [Beautiful Soup] 가져온 코드 Text화해서 리스트에 추가하기\n",
    "for b in content:\n",
    "    print(b.text)\n",
    "# NextPage = driver.find_element_by(\"a-size-base a-color-base a-text-normal\") \n",
    "# NextPage.click()\n",
    "\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49e04899c6e094c3b61dd8509fde2649571811ca1eef12c1c216e72ad0930740"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
